# Database Configuration
# Path to SQLite database file (default: ./data/tasks.db)
DB_PATH=./data/tasks.db

# vLLM AI Service Configuration
# Base URL for vLLM API server (default: http://localhost:8000)
VLLM_BASE_URL=http://localhost:8000

# Hugging Face Configuration
# Required for downloading AI models from Hugging Face
# Get your token from: https://huggingface.co/settings/tokens
HUGGING_FACE_HUB_TOKEN=your_huggingface_token_here

# Application Configuration
# Node environment (development, production, test)
NODE_ENV=development

# Server Configuration
# Port for the Next.js application (default: 5432)
PORT=5432
# Hostname for the server (default: 0.0.0.0)
HOSTNAME=0.0.0.0

# Optional: Custom AI Model Configuration
# Override the default AI model name
# VLLM_MODEL_NAME=Qwen/Qwen3-Coder-30B

# Optional: GPU Configuration for vLLM
# GPU memory utilization percentage (default: 0.9)
# VLLM_GPU_MEMORY_UTILIZATION=0.9
# Maximum model length in tokens (default: 8192)
# VLLM_MAX_MODEL_LEN=8192
